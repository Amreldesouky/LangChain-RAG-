# ğŸ§  Local RAG System with LangChain, Phi-3, and CSV

This project implements a **fully local Retrieval-Augmented Generation (RAG) system** that allows you to **chat with structured CSV data** â€” no APIs, no cloud, just fast and private Q&A from your own machine.

## ğŸ“Œ Description

This system uses:

- ğŸ”— **LangChain** for retrieval pipeline
- ğŸ¤– **Phi-3** (via Ollama) as the local language model
- ğŸ§  **HuggingFace Embeddings** (all-MiniLM-L6-v2)
- ğŸ’¾ **ChromaDB** for persistent vector storage
- ğŸ“‚ **CSV** file as the knowledge base

Ask natural questions like:
> "What is Michael Brown's position?"  
> "Who works in the Engineering department?"  
> "When did Sara Lee join?"

And get answers instantly â€” grounded in your own data.

---

## ğŸ› ï¸ How It Works

1. **Loads CSV** and converts rows to documents.
2. **Embeds text** using MiniLM from HuggingFace.
3. **Stores vectors** in ChromaDB locally.
4. **Retrieves relevant chunks** based on user query.
5. **Generates answer** using Phi-3 via Ollama.

---

## ğŸš€ Setup Instructions

1. **Install dependencies:**
   ```bash
   pip install langchain langchain-community chromadb
   pip install sentence-transformers pandas
